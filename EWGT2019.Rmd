---
title: "EWGT2019"
author: "Dmitry Pavlyuk"
date: "February 6, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

This markdown document reproduces the research "Ensemble learning of the spatiotemporal structure of urban traffic
flows", submitted to EURO Working Group on Transportation Meeting, EWGT 2019


```{r child='sampling.Rmd'}
```


Load necessary libraries
----------------
```{r libs}
memory.limit(size=1024*128)
library(needs)
needs(knitr)
needs(tidyverse)
needs(reshape2)
needs(ggplot2)
needs(geosphere)
needs(igraph)
needs(Metrics)
needs(imputeTS)
needs(e1071)
needs(MTS)
needs(forecast)
needs(doParallel)
needs(glasso)
needs(scales)
needs(stringr)

source(file.path("R","prepare_data_functions.R"))
source(file.path("R","cv_functions.R"))
source(file.path("R","cv_utils.R"))
source(file.path("R","models_util.R"))
source(file.path("R","models_baseline.R"))
source(file.path("R","models_spvar.R"))


# Define files for intermediate results
models.estimated.file <- "EWGT2019.models.estimated.rds"
results.file <- "EWGT2019.results.rds"
fs.file <- "EWGT2019.fs.rds"
summary.file <- "EWGT2019.summary.rds"
```


```{r models}
RunModels <- function(data, series, ta, forecastingSteps, forecastEvery,
                      validationSize, validationEnd, 
                      lagMatrix, cvgrid, 
                      models.estimated.file, results.file,save.links.file){
  start.time <- Sys.time()
  
  results<-tibble()
  models.estimated <- c()
  if (file.exists(models.estimated.file)) models.estimated <- readRDS(models.estimated.file)
  if (file.exists(results.file)) results <- readRDS(results.file)
  
  for (r in 1:nrow(cvgrid)){
    cv <- cvgrid[r,]
    print(paste("Tuned parameter's set",r,"of",nrow(cvgrid)))
    print(cv)
    validationStart <- validationEnd - validationSize
    trainingSize <- cv$trainingMinutes/ta
    dat.restricted<-data[(validationStart-trainingSize+1):validationEnd,]
    base_params<-list(data=dat.restricted, seriesNames=series, 
                      forecastingSteps=forecastingSteps, forecastEvery=forecastEvery)
    params<-c(base_params,list(trainingWindowSize=trainingSize))

    #HA
    modelid <- paste(xModel.zero$name,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=xModel.zero)),
               envir=environment())
      results<-bind_rows(results,res)
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    #Simple mean
    modelid <- paste(xModel.mean$name,cv$trainingMinutes,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=xModel.mean)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    
    #MA
    modelid <- paste(xModel.ma$name,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=xModel.ma)),
               envir=environment())
      results<-bind_rows(results,res)
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
  
    #Naive
    modelid <- paste(xModel.naive$name,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=xModel.naive)),
               envir=environment())
      results<-bind_rows(results,res)
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    #Auto arima
    modelid <- paste(xModel.autoarima$name,cv$trainingMinutes,
                     cv$include.mean,cv$stationary,cv$allowdrift,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=xModel.autoarima,
                             allowmean=cv$include.mean,
                             stationary=cv$stationary,
                             allowdrift=cv$allowdrift)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes,include.mean=cv$include.mean,
                             stationary=cv$stationary,
                             allowdrift=cv$allowdrift))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    # Glasso
    modelid <- paste(suf(xModel.star,"glasso")$name,cv$trainingMinutes,
                     cv$arLags,cv$glassoRho,cv$include.mean,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=suf(xModel.star,"glasso"),matrixMode="glasso",
                             control=list(glassoRho=cv$glassoRho),
                             arLags=cv$arLags,include.mean=cv$include.mean,save_links_file=save.links.file)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes,arLags=cv$arLags,
                         include.mean=cv$include.mean,glassoRho=cv$glassoRho))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    # Travel time
    modelid <- paste(suf(xModel.star,"travelTime")$name,cv$trainingMinutes,
                     cv$arLags,cv$include.mean,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=suf(xModel.star,"travelTime"),matrixMode="travelTime",
                             control=list(lagMatrix=lagMatrix),
                             arLags=cv$arLags,include.mean=cv$include.mean,save_links_file=save.links.file)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes,arLags=cv$arLags,
                         include.mean=cv$include.mean))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    # CCF
    modelid <- paste(suf(xModel.star,"ccf")$name,cv$trainingMinutes,
                     cv$arLags,cv$ccfThreshold,cv$include.mean,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=suf(xModel.star,"ccf"),matrixMode="CCF",
                             control=list(ccfThreshold=cv$ccfThreshold),
                             arLags=cv$arLags,include.mean=cv$include.mean,save_links_file=save.links.file)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes,arLags=cv$arLags,
                         include.mean=cv$include.mean,ccfThreshold=cv$ccfThreshold))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    # Ensemble
    modelid <- paste(suf(xModel.star,"ensemble")$name,cv$trainingMinutes,
                     cv$arLags,cv$glassoRho,cv$ccfThreshold,
                     cv$include.mean,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=suf(xModel.star,"ensemble"),matrixMode=c("glasso","CCF", "travelTime"),
                             control=list(glassoRho=cv$glassoRho,lagMatrix=lagMatrix,ccfThreshold=cv$ccfThreshold),
                             arLags=cv$arLags,include.mean=cv$include.mean,save_links_file=save.links.file)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes,arLags=cv$arLags,
                         include.mean=cv$include.mean,glassoRho=cv$glassoRho,ccfThreshold=cv$ccfThreshold))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    # Complete
    modelid <- paste(suf(xModel.star,"complete")$name,cv$trainingMinutes,
                     cv$arLags, cv$include.mean,collapse = '')
    if (!(modelid %in% models.estimated)){
      print(paste("Estimating model",modelid))
      res<-do.call(rollingWindow,
               c(params,list(xModel=suf(xModel.star,"complete"),matrixMode="complete",
                             control=list(),
                             arLags=cv$arLags,include.mean=cv$include.mean)),
               envir=environment())
      results<-bind_rows(results,res%>%mutate(trainingMinutes=cv$trainingMinutes,arLags=cv$arLags,
                         include.mean=cv$include.mean))
      models.estimated<-c(models.estimated,modelid)
      saveRDS(results, results.file)
      saveRDS(models.estimated, models.estimated.file)
    }else{
      print(paste("Model",modelid,"already estimated; skipped"))
    }
    
    print(Sys.time() - start.time)
  }
}
```

```{r experiments}

# Read sample data
series <- colnames(mysample$data)[-1]
print(paste("Number of series", length(series)))

# Prepare a matrix of maximal lags (for travel time regularisation)
lagMatrix <- round(mysample$shortest.distances / ta)
lagMatrix[is.infinite(lagMatrix)]<-0
rownames(lagMatrix)<-paste0(rownames(lagMatrix),".volume")
colnames(lagMatrix)<-paste0(colnames(lagMatrix),".volume")
lagMatrix<-lagMatrix[as.vector(series),as.vector(series)]


# Define validation sample (10 weeks - 1 day at the beginning)
validationSize <- nrow(mysample$data)-1*24*60/ta
validationEnd <- nrow(mysample$data)
forecastEvery<-20
forecastingSteps<-3

# Do not save features - just search for optimal model specifications
save.links.file <- NULL




# Preliminary search results:
# arLag=9 is ineffective (because the area is limited with 6 minutes, decided to limit arLag search by 1,3,6
# trainingMinutes=7*24*60 is ineffective,decided to use 720-minutes lookback (necessary for 6-lag models) 
# Sample size - 480 wins against 720 for all arLag=3, except complete VAR
# glassoRho=0.01 is ineffective, glassoRho=0.5 is ineffective
# ccfThreshold<0.7 ineffective

# Define a grid for tuning parameters
ccfThresholds <- c(0.1, 0.3, 0.5)
glassoRhos <- c(0.05, 0.1, 0.3)
means <- c(F)
ar_orders <- c(1, 3)
stationary <- c(F)
allowdrift <- c(F)
trainingMinutes <- c(480)

cvgrid <- expand.grid(trainingMinutes = trainingMinutes,
                        glassoRho = glassoRhos, ccfThreshold=ccfThresholds, 
                        include.mean = means, arLags = ar_orders,
                        stationary = stationary,
                        allowdrift = allowdrift)

# Run all models
RunModels(mysample$data, series, ta, forecastingSteps, forecastEvery,
                      validationSize, validationEnd, 
                      lagMatrix, cvgrid, 
                      models.estimated.file, results.file,save.links.file)
# Choose models with optimal sets of tuned parameters for arLargs=3
params <- c('trainingMinutes','allowdrift','stationary','arLags','glassoRho','ccfThreshold','include.mean')

# Read estimation results
results <- readRDS(results.file)
models.estimated <- readRDS(models.estimated.file)
s<-cvSummary(results, mae, cumulative=T, params=params)%>%
    mutate(modelid=paste(model,trainingMinutes, arLags,glassoRho, ccfThreshold,include.mean,stationary,allowdrift))%>%
    mutate(modelid=gsub(" NA","",modelid))
saveRDS(s, summary.file)



winners3 <- s%>%
    filter(forecast_horizon==3,arLags==3)%>%
    group_by(model)%>%filter(MAE==min(MAE))%>%ungroup

# Re-estimate best model specification, saving features on every step
  reestimate.ids <- winners3%>%
    filter(model %in% c("STAR ccf", "STAR glasso", "STAR ensemble", "STAR travelTime"))%>%select(modelid)%>%pull

  save.links.file <- file.path("fs", fs.file)
  tmp.models.estimated.file <- "tmp.EWGT2019.models.estimated.rds"
  tmp.results.file <- "tmp.EWGT2019.results.rds"
  if (file.exists(save.links.file)) file.remove(save.links.file)
  saveRDS(models.estimated[! models.estimated %in% reestimate.ids], tmp.models.estimated.file)
  if (file.exists(tmp.results.file)) file.remove(tmp.results.file)
  
  
  RunModels(mysample$data, series, ta, forecastingSteps, forecastEvery,
                      validationSize, validationEnd, 
                      lagMatrix, cvgrid, 
                      tmp.models.estimated.file, tmp.results.file,save.links.file)
  
  
  # Combine features from individual models
  fs.tib <- tibble()
  ls <- list.files(path="fs100")
  cou<-0
  for (i in ls){
    rf <- readRDS(file.path("fs100", i))
    pars<- rf%>%first%>%select(training_minutes,max_lag)
    #if (pars$max_lag==3){
      cou<-cou+1
      fs.tib<-bind_rows(fs.tib,rf)
       print(cou)
      # if (cou %% 100 == 0){
      #    saveRDS(fs.tib, file.path("fs100",paste0("fs.rds", cou)))
      #    fs.tib <- tibble()
      # }
    #}
  }
  #if (nrow(fs.tib)>0) saveRDS(fs.tib, file.path("fs100",paste0("fs.rds", cou)))
  if (nrow(fs.tib)>0) saveRDS(fs.tib, fs.file)
  
  fs.tib<-fs.tib%>%mutate(modelid=paste(ifelse(fs=="CCF","ccf",fs),training_minutes,max_lag,glasso_rho, ccf_threshold,include_mean))%>%
    mutate(last_date = as.POSIXct(last_date, "%Y-%m-%d %H:%M:%S",tz="GMT"))%>%
    mutate(modelid=gsub(" NA","",modelid))
  saveRDS(fs.tib, fs.file)
  
```

```{r draw_graph}

series <- colnames(mysample$data)[-1]
res<-find_paths(gsub(".volume","",series), mysample$links)
df <- res%>%left_join(mysample$config.nodes, by=c("from"="node_name"), suffix=c(".from", ".to"))%>%left_join(mysample$config.nodes, by=c("to"="node_name"), suffix=c(".from", ".to"))%>%
  select(from, to, distance,time,startx=node_lon.from,starty=node_lat.from,endx=node_lon.to,endy=node_lat.to)
write.csv(df,"EWGT2019.links.csv", row.names = F)
write.csv(mysample$config.nodes,"EWGT2019.nodes.csv", row.names = F)

```

```{r results}

# Load experimental results
fs.tib <- readRDS(fs.file)
results <- readRDS(results.file)

source(file.path("R","cv_functions.R"))

params <- c('trainingMinutes','allowdrift','stationary','arLags','glassoRho','ccfThreshold','include.mean')

# Load summary statistics (or calcuklate them if files are absent)
if (file.exists(summary.file)){
  s <- readRDS(summary.file)
} else {
  s.mae<-cvSummary(results, mae, cumulative=T, params=params)
  s.rmse<-cvSummary(results, rmse, cumulative=T, params=params)
  s.mase<-cvSummary(results, mase, cumulative=T, params=params)
  
  s.mae<-s.mae%>%mutate(modelid=paste(model,trainingMinutes, arLags,glassoRho, ccfThreshold,include.mean,stationary,allowdrift))%>%mutate(modelid=gsub(" NA","",modelid))
  s.rmse<-s.rmse%>%mutate(modelid=paste(model,trainingMinutes, arLags,glassoRho, ccfThreshold,include.mean,stationary,allowdrift))%>%mutate(modelid=gsub(" NA","",modelid))
  s.mase<-s.mase%>%mutate(modelid=paste(model,trainingMinutes, arLags,glassoRho, ccfThreshold,include.mean,stationary,allowdrift))%>%mutate(modelid=gsub(" NA","",modelid)) 
  s<-list(s.mae=s.mae, s.rmse=s.rmse,s.mase=s.mase)
  # Save summary statistics for further usage
  write.csv(s$s.mae%>%select(-q95)%>%spread(key=forecast_horizon,value=MAE)%>%group_by(model)%>%filter(`3`==min(`3`))%>%arrange(`3`), "EWGT2019.mae.csv")
  write.csv(s2%>%select(-q95)%>%spread(key=forecast_horizon,value=RMSE)%>%group_by(model)%>%filter(`3`==min(`3`))%>%arrange(`3`), "EWGT2019.rmse.csv")
  saveRDS(s, summary.file)
}

# Choose best models of a kind
winners <- s$s.mae%>%filter(forecast_horizon==3, arLags == 3)%>%group_by(model)%>%filter(MAE==min(MAE))%>%ungroup
star.models <- winners%>%filter(model %in% c("STAR ccf", "STAR glasso", "STAR ensemble", "STAR travelTime"))%>%select(modelid)%>%pull

# Filter and rename models for presentation purposes
fs.tib.filtered <- fs.tib%>%filter(value>0)%>%filter(modelid %in% gsub("STAR ","",star.models))%>%
    mutate(maxn=ncol(mysample$data))%>%mutate(maxn=ifelse(str_detect(modelid,"^glasso"),3*maxn*maxn,maxn*(3+maxn)))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^ccf"),"Cross-correlation filtering",modelid))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^ensemble"),"Ensemble filtering",modelid))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^glasso"),"Graphical LASSO filtering",modelid))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^travel"),"Travel time filtering",modelid))%>%
    mutate(wd=weekdays(last_date))

  
 # Plot number of features per time 
fs.tib.filtered%>%group_by(modelid,last_date)%>%
    summarise(n=n())%>%arrange(modelid, last_date)%>%
    ggplot(aes(x = last_date, y = n, col=modelid, group=modelid)) + geom_line()

# Plot weekly pattern for number of features
fs.tib.filtered%>%group_by(modelid,last_date)%>%
    summarise(n=n(),maxn=last(maxn))%>%ungroup%>%
    mutate(last_date_d = format(last_date, format="%a %H:%M",tz="GMT"))%>%
    group_by(modelid,last_date_d)%>%
    summarise(mn=mean(n/maxn), ld=last(last_date))%>%
    ggplot(aes(x = ld, y = mn, col=modelid, group=modelid)) + 
    geom_line(size=1) +
    scale_x_datetime(labels = date_format("%a %H:%M"), date_breaks = "12 hours") + 
    labs(x = "Week day, time of the day", y="Mean sparsity (share of used features)", colour="Feature selection")

# Plot daily pattern for number of features for week days
fs.tib.filtered%>%filter(!(wd %in% c("Sunday","Saturday")))%>%
    group_by(modelid,last_date)%>%
    summarise(n=n(),maxn=last(maxn))%>%
    mutate(last_date_d = format(last_date, format="%H:%M",tz="GMT"))%>%
    group_by(modelid,last_date_d)%>%
    summarise(mn=mean(n/maxn), ld=last(last_date))%>%
    ggplot(aes(x = ld, y = mn, col=modelid, group=modelid)) + 
    geom_line(size=1)+
    scale_x_datetime(labels = date_format("%H:%M"), date_breaks = "3 hours")+ 
    labs(x = "Time of the day", y="Mean sparsity (share of used features)", colour="Feature selection")


# Calculate cummulative results
cummulative.results.file <-"EWGT2019.results-cum.rds"
if (file.exists(cummulative.results.file)){
  results.cum <- readRDS(cummulative.results.file)
}else{
  results.cum <-results%>%
    mutate(modelid=gsub(" NA","",paste(model,trainingMinutes, arLags,glassoRho, ccfThreshold,include.mean,stationary,allowdrift)))%>%
    group_by(model_hash,detector)%>%
    arrange(model_hash,detector,forecast_horizon)%>%
    mutate(cumactual=cumsum(actual),cumforecasted=cumsum(forecasted))
  saveRDS(results.cum, cummulative.results.file)
}
 
m<-c("Cross-correlation filtering","Ensemble filtering","Graphical LASSO filtering", "Travel time filtering")
g <- c('model',params) 

results.cum.filtered<-results.cum%>%filter(forecast_horizon==3,modelid %in% star.models)%>%
    mutate(modelid=ifelse(str_detect(modelid,"^STAR ccf"),"Cross-correlation filtering",modelid))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^STAR ensemble"),"Ensemble filtering",modelid))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^STAR glasso"),"Graphical LASSO filtering",modelid))%>%
    mutate(modelid=ifelse(str_detect(modelid,"^STAR travel"),"Travel time filtering",modelid))
saveRDS(results.cum.filtered,paste0(cummulative.results.file,".filtered"))

# Group MAE values spatially (by model and datetime)
gtmp<-results.cum.filtered%>%group_by(modelid,datetime)%>%summarise(mn=mae(cumactual,cumforecasted))
  
# Plot temporal dynamic of mean MAE values  
  gtmp%>%
    ggplot(aes(x = datetime, y = mn, col=modelid, group=modelid)) + geom_line()+
    scale_x_datetime(labels = date_format("%d-%m %H:%M"), date_breaks = "1 day")
  
# Group MAE value temporary - by time of the day                                                                      
  gtmp1<-gtmp%>%filter(modelid %in% m)%>%mutate(last_date_d = format(datetime, format="%H:%M",tz="GMT"))%>%
    group_by(modelid,last_date_d)%>%
    summarise(meann=mean(mn), ld=last(datetime))
  
# Plot daily patterns of MAE values  
  gtmp1%>%ggplot(aes(x = ld, y = meann, col=modelid, group=modelid)) + geom_line(size=1) +
    scale_x_datetime(labels = date_format("%H:%M"), date_breaks = "3 hours") + 
    labs(x = "Time of the day", y="Mean MAE", colour="Feature selection")
    
# Plot differences in daily patterns of models' mean MAE values
  gtmp1%>%spread(key=modelid,value=meann)%>%
    mutate(`CCF vs. Ensemble`=`Cross-correlation filtering`-`Ensemble filtering`)%>%
    mutate(`Travel time vs. Ensemble`=`Travel time filtering`-`Ensemble filtering`)%>%
    #mutate(`Graphical LASSO vs. Ensemble`=`Graphical LASSO filtering`-`Ensemble filtering`)%>%
    select(ld,`CCF vs. Ensemble`,`Travel time vs. Ensemble`)%>%
    gather(`CCF vs. Ensemble`,`Travel time vs. Ensemble`,key="modelid", value="Difference")%>%
    ggplot(aes(x = ld, y = Difference, col=modelid, group=modelid)) + 
    geom_line(size=1)+scale_x_datetime(labels = date_format("%H:%M"), date_breaks = "3 hours")+
    labs(x = "Time of the day", y="Mean MAE difference", colour="Feature selection") + geom_hline(yintercept=0)
  
  
# Test the hypothesis about MAE
gtmpX<-results.cum.filtered%>%mutate(last_date_d = format(datetime, format="%H:%M",tz="GMT"))

  stat.results<-gtmpX%>%group_by(modelid,last_date_d)%>%
  summarise(meann=mean(abs(cumactual-cumforecasted)),sd=sd(abs(cumactual-cumforecasted)), n=n(),ld=max(datetime))%>%
    gather(variable, value, -c(modelid,last_date_d, ld))%>%
    unite(tmp, modelid, variable)%>%
    spread(tmp,value)%>%mutate(ccf_ensemble_t=(`Cross-correlation filtering_meann`-`Ensemble filtering_meann`)/sqrt(`Cross-correlation filtering_sd`^2/`Cross-correlation filtering_n`+`Ensemble filtering_sd`^2/`Ensemble filtering_n`))%>%
    mutate(travelTime_ensemble_t=(`Travel time filtering_meann`-`Ensemble filtering_meann`)/sqrt(`Travel time filtering_sd`^2/`Travel time filtering_n`+`Ensemble filtering_sd`^2/`Ensemble filtering_n`))%>%
    mutate(glasso_ensemble_t=(`Graphical LASSO filtering_meann`-`Ensemble filtering_meann`)/sqrt(`Graphical LASSO filtering_sd`^2/`Travel time filtering_n`+`Ensemble filtering_sd`^2/`Ensemble filtering_n`))%>%
    mutate(`Travel time vs. Ensemble`=`Travel time filtering_meann`-`Ensemble filtering_meann`,
           `CCF vs. Ensemble`=`Cross-correlation filtering_meann`-`Ensemble filtering_meann`,
           `Graphical LASSO vs. Ensemble`=`Graphical LASSO filtering_meann`-`Ensemble filtering_meann`)%>%
    select(`Travel time vs. Ensemble`,travelTime_ensemble_t, `CCF vs. Ensemble`, ccf_ensemble_t,
           `Graphical LASSO vs. Ensemble`,glasso_ensemble_t)%>%summary
  
  write.csv(stat.results, "EWGT2019.hypotheses.csv")
  
```